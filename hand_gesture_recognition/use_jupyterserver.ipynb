{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n",
      "100%|██████████| 39/39 [00:16<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import cv2 as cv\n",
    "import time\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "import torchvision.transforms\n",
    "import pytorchvideo.transforms\n",
    "import wandb\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    seed = 42\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    num_workers = 0\n",
    "    batch_size = 4\n",
    "    pin_memory = False\n",
    "\n",
    "    lr = 1e-3\n",
    "    epochs = 15\n",
    "    image_size = 256\n",
    "    num_frame = 8\n",
    "    \n",
    "    model_name = 'slow_r50'\n",
    "    # model_name = 'slowfast_r101'\n",
    "    # model_name = 'slowfast_16x8_r101_50_50'\n",
    "    \n",
    "    data_path = '/datasets/dacon-hand-recog'\n",
    "    load_path = None\n",
    "    load_path = 'slow_r50(3).pt'\n",
    "    save_path = 'slow_r50(5).pt'\n",
    "    # save_path = 'slowfast_r101(0).pt'\n",
    "    # save_path = 'slow_16x8_r101(1).pt'\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def train_loop(data_loader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for X, y in tqdm(data_loader):\n",
    "        X = X.to(Config.device)\n",
    "        y = y.to(Config.device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "\n",
    "    logging.info(f'loss: {np.mean(losses):7.3f}')\n",
    "\n",
    "def valid_loop(data_loader, model, loss_fn):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(data_loader):\n",
    "            X = X.to(Config.device)\n",
    "            y = y.to(Config.device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            losses.append(loss.item())\n",
    "            preds.extend(pred.argmax(1).cpu().numpy())\n",
    "            trues.extend(y.cpu())\n",
    "            correct += (pred.argmax(1) == y).sum().item()\n",
    "    \n",
    "    valid_loss = np.mean(losses)\n",
    "    valid_score = sklearn.metrics.f1_score(trues, preds, average='macro')\n",
    "    logging.info(f'correct: {correct:3} / {len(data_loader.dataset)}, validation_loss: {valid_loss:7.3f}, validation_score: {valid_score:7.3f}')\n",
    "    return valid_loss, valid_score\n",
    "\n",
    "def test_loop(data_loader, model):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for X in tqdm(data_loader):\n",
    "        X = X.to(Config.device)\n",
    "        pred = model(X)\n",
    "        preds.extend(pred.argmax(1).cpu().numpy())\n",
    "    submit = pd.read_csv('./sample_submission.csv')\n",
    "    submit['label'] = preds\n",
    "    submit.to_csv('./resnet_submission.csv', index=False)\n",
    "\n",
    "def save_state_dict(path, model, optimizer, scheduler):\n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler': scheduler.state_dict(),\n",
    "    }, path)\n",
    "\n",
    "def load_state_dict(path, model, optimizer, scheduler):\n",
    "    data = torch.load(path)\n",
    "    model.load_state_dict(data['model'])\n",
    "    optimizer.load_state_dict(data['optimizer'])\n",
    "    scheduler.load_state_dict(data['scheduler'])\n",
    "\n",
    "class VideoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, labels=None, frame_transforms=None, video_transforms=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.frame_transforms = frame_transforms\n",
    "        self.video_transforms = video_transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        video = self.get_video(os.path.join(Config.data_path, os.path.basename(self.paths[index])))\n",
    "        if self.labels is None:\n",
    "            return video\n",
    "            \n",
    "        label = self.labels[index]\n",
    "        return video, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def get_video(self, path):\n",
    "        cap = cv.VideoCapture(path)\n",
    "        video = []\n",
    "        while True:\n",
    "            ret: bool; frame: np.ndarray\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if self.frame_transforms is not None:\n",
    "                frame = self.frame_transforms(frame)\n",
    "            video.append(frame)\n",
    "        \n",
    "        video = torch.cat([frame.unsqueeze(1) for frame in video], 1)\n",
    "        \n",
    "        if self.video_transforms is not None:\n",
    "            video = self.video_transforms(video)\n",
    "        return video\n",
    "\n",
    "class PackPathway(torch.nn.Module):\n",
    "    def __init__(self, alpha):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, x):\n",
    "        fast = torch.index_select(x, 1, torch.linspace(0, x.shape[1] - 1, Config.num_frame).long())\n",
    "        slow = torch.index_select(x, 1, torch.linspace(0, x.shape[1] - 1, Config.num_frame // self.alpha).long())\n",
    "        return [slow, fast]\n",
    "\n",
    "def get_dataloader():\n",
    "    df = pd.read_csv(os.path.join(Config.data_path, 'train.csv'))\n",
    "    train_df, valid_df = sklearn.model_selection.train_test_split(df, test_size=0.2, random_state=Config.seed)\n",
    "    test_df = pd.read_csv(os.path.join(Config.data_path, 'test.csv'))\n",
    "\n",
    "    train_paths: np.ndarray = train_df['path'].to_numpy()\n",
    "    valid_paths: np.ndarray = valid_df['path'].to_numpy()\n",
    "    test_paths: np.ndarray = test_df['path'].to_numpy()\n",
    "    train_labels: np.ndarray = train_df['label'].to_numpy()\n",
    "    valid_labels: np.ndarray = valid_df['label'].to_numpy()\n",
    "\n",
    "    frame_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.Resize((Config.image_size, Config.image_size)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Lambda(lambda x: x / 255),\n",
    "    ])\n",
    "    video_transforms = pytorchvideo.transforms.UniformTemporalSubsample(Config.num_frame)\n",
    "    # video_transforms = PackPathway(4)\n",
    "\n",
    "    train_dataset = VideoDataset(train_paths, train_labels, frame_transforms=frame_transforms, video_transforms=video_transforms)\n",
    "    valid_dataset = VideoDataset(valid_paths, valid_labels, frame_transforms=frame_transforms, video_transforms=video_transforms)\n",
    "    test_dataset = VideoDataset(test_paths, frame_transforms=frame_transforms, video_transforms=video_transforms)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True, num_workers=Config.num_workers)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "def get_dataloader_kfold(k=5):\n",
    "    df = pd.read_csv(os.path.join(Config.data_path, 'train.csv'))\n",
    "    kf = sklearn.model_selection.KFold(k, shuffle=True, random_state=Config.seed)\n",
    "    train_indices, valid_indices = [], []\n",
    "    for train_idx, valid_idx in kf.split(df):\n",
    "        train_indices.append(train_idx)\n",
    "        valid_indices.append(valid_idx)\n",
    "\n",
    "    train_df = [df.loc[train_idx] for train_idx in train_indices]\n",
    "    valid_df = [df.loc[valid_idx] for valid_idx in valid_indices]\n",
    "    test_df = pd.read_csv(os.path.join(Config.data_path, 'test.csv'))\n",
    "\n",
    "    train_paths = [df['path'].to_numpy() for df in train_df]\n",
    "    valid_paths = [df['path'].to_numpy() for df in valid_df]\n",
    "    test_paths: np.ndarray = test_df['path'].to_numpy()\n",
    "    train_labels = [df['label'].to_numpy() for df in train_df]\n",
    "    valid_labels = [df['label'].to_numpy() for df in valid_df]\n",
    "\n",
    "    frame_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.Resize((Config.image_size, Config.image_size)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Lambda(lambda x: x / 255),\n",
    "    ])\n",
    "    # video_transforms = PackPathway(4)\n",
    "    video_transforms = pytorchvideo.transforms.UniformTemporalSubsample(Config.num_frame)\n",
    "\n",
    "    train_dataset = [VideoDataset(paths, labels, frame_transforms=frame_transforms, video_transforms=video_transforms) for paths, labels in zip(train_paths, train_labels)]\n",
    "    valid_dataset = [VideoDataset(paths, labels, frame_transforms=frame_transforms, video_transforms=video_transforms) for paths, labels in zip(valid_paths, valid_labels)]\n",
    "    test_dataset = VideoDataset(test_paths, frame_transforms=frame_transforms, video_transforms=video_transforms)\n",
    "\n",
    "    train_loader = [torch.utils.data.DataLoader(dataset, batch_size=Config.batch_size, shuffle=True, num_workers=Config.num_workers) for dataset in train_dataset]\n",
    "    valid_loader = [torch.utils.data.DataLoader(dataset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers) for dataset in valid_dataset]\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "def train_model():\n",
    "    wandb.init(project=\"video-hand-gesture-classification\", entity=\"seokjin\")\n",
    "    wandb.config = {\n",
    "        'model_name': Config.model_name,\n",
    "        'num_frame': Config.num_frame,\n",
    "        'image_size': Config.image_size,\n",
    "    }\n",
    "    train_loader, valid_loader, test_loader = get_dataloader()\n",
    "    \n",
    "    model = torch.hub.load('facebookresearch/pytorchvideo', Config.model_name, pretrained=True)\n",
    "    model = torch.nn.Sequential(model, torch.nn.Linear(400, 5, bias=True))\n",
    "    \n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=Config.lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "    model.to(Config.device)\n",
    "    if Config.load_path:\n",
    "        load_state_dict(Config.load_path, model, optimizer, scheduler)\n",
    "    \n",
    "    best_score = 0\n",
    "    for i in range(Config.epochs):\n",
    "        train_loop(train_loader, model, loss_fn, optimizer)\n",
    "        loss, score = valid_loop(valid_loader, model, loss_fn)\n",
    "        scheduler.step(loss)\n",
    "        if score > best_score:\n",
    "            save_state_dict(Config.save_path, model, optimizer, scheduler)\n",
    "            best_score = score\n",
    "        \n",
    "        wandb.log({\n",
    "            'loss': loss,\n",
    "            'score': score,\n",
    "            'lr': scheduler._last_lr[0],\n",
    "        })\n",
    "        wandb.watch(model)\n",
    "\n",
    "def train_model_kfold():\n",
    "    k = 5\n",
    "    train_loader, valid_loader, test_loader = get_dataloader_kfold(k)\n",
    "    for fold in reversed(range(k)):\n",
    "        kfold_message = f'{fold}fold'\n",
    "        logging.info(f'{kfold_message:-^20}')\n",
    "        wandb.init(project=\"video-hand-gesture-classification\", entity=\"seokjin\")\n",
    "        wandb.config = {\n",
    "            'model_name': Config.model_name,\n",
    "            'num_frame': Config.num_frame,\n",
    "            'image_size': Config.image_size,\n",
    "        }\n",
    "        \n",
    "        model = torch.hub.load('facebookresearch/pytorchvideo', Config.model_name, pretrained=True)\n",
    "        model = torch.nn.Sequential(model, torch.nn.Linear(400, 5, bias=True))\n",
    "        \n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=Config.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "        model.to(Config.device)\n",
    "        if Config.load_path:\n",
    "            load_state_dict(Config.load_path, model, optimizer, scheduler)\n",
    "        \n",
    "        best_score = 0\n",
    "        for i in range(Config.epochs):\n",
    "            train_loop(train_loader[fold], model, loss_fn, optimizer)\n",
    "            loss, score = valid_loop(valid_loader[fold], model, loss_fn)\n",
    "            scheduler.step(loss)\n",
    "            if score > best_score:\n",
    "                save_state_dict(f'{Config.save_path}_{fold}fold', model, optimizer, scheduler)\n",
    "                best_score = score\n",
    "            \n",
    "            wandb.log({\n",
    "                'loss': loss,\n",
    "                'score': score,\n",
    "                'lr': scheduler._last_lr[0],\n",
    "            })\n",
    "            wandb.watch(model)\n",
    "\n",
    "def test_model():\n",
    "    train_loader, valid_loader, test_loader = get_dataloader()\n",
    "    \n",
    "    model = torch.hub.load('facebookresearch/pytorchvideo', Config.model_name, pretrained=True)\n",
    "    model = torch.nn.Sequential(model, torch.nn.Linear(400, 5, bias=True))\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=Config.lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "    model.to(Config.device)\n",
    "    if Config.load_path:\n",
    "        load_state_dict(Config.load_path, model, optimizer, scheduler)\n",
    "    \n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for X in tqdm(test_loader):\n",
    "        X = X.to(Config.device)\n",
    "        pred = model(X)\n",
    "        preds.extend(pred.argmax(1).cpu().numpy())\n",
    "    submit = pd.read_csv(os.path.join(Config.data_path, 'sample_submission.csv'))\n",
    "    submit['label'] = preds\n",
    "    submit.to_csv(f'./{Config.load_path}_submission.csv', index=False)\n",
    "\n",
    "def test_model_kfold():\n",
    "    k = 5\n",
    "    train_loader, valid_loader, test_loader = get_dataloader()\n",
    "\n",
    "    soft_vote = []\n",
    "\n",
    "    for fold in range(k):\n",
    "        model = torch.hub.load('facebookresearch/pytorchvideo', Config.model_name, pretrained=True)\n",
    "        model = torch.nn.Sequential(model, torch.nn.Linear(400, 5, bias=True))\n",
    "\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=Config.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "        model.to(Config.device)\n",
    "        if Config.load_path:\n",
    "            load_state_dict(f'{Config.load_path}_{fold}fold', model, optimizer, scheduler)\n",
    "        \n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for X in tqdm(test_loader):\n",
    "            X = X.to(Config.device)\n",
    "            pred = model(X)\n",
    "            preds.extend(pred.cpu().numpy())\n",
    "        preds = np.array(preds)\n",
    "        soft_vote.append(preds)\n",
    "    \n",
    "    ensampled = np.sum(soft_vote, 0)\n",
    "    ensampled = np.argmax(ensampled, 1)\n",
    "    \n",
    "    submit = pd.read_csv(os.path.join(Config.data_path, 'sample_submission.csv'))\n",
    "    submit['label'] = ensampled\n",
    "    submit.to_csv(f'./{Config.load_path}_submission.csv', index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(filename='logging.log', encoding='utf8', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logging.info(f'{\"Run\":-^20}')\n",
    "    seed_everything(Config.seed)\n",
    "    # train_model_kfold()\n",
    "    # train_model()\n",
    "    test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
